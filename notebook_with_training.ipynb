{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DIP_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 245.71780199999998,
      "position": {
        "height": "244.712px",
        "left": "727.067px",
        "right": "20px",
        "top": "142.965px",
        "width": "596.006px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "block",
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK07UF2BNUjb",
        "outputId": "5a30957b-ed17-4059-c3ec-c993aad126e6"
      },
      "source": [
        "%config IPCompleter.greedy=True\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\";\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQhqS7FWNUjp"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-NpoDCJSul"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io\n",
        "import glob\n",
        "from scipy.io import loadmat\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import os\n",
        "import os.path\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import math\n",
        "from skimage import io, transform\n",
        "from collections import namedtuple\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "import shutil\n",
        "import codecs \n",
        "import timeit\n",
        "from tqdm import tqdm\n",
        "import progressbar\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvBXoOp8wuf2",
        "outputId": "37d317dd-4afd-4421-8de7-7ae14d70792c"
      },
      "source": [
        "device = torch.device(\"cuda\") \n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wc_frul1Cv1"
      },
      "source": [
        "## ConvNet class\n",
        "###our convolution class contain the architecture of our cnn neural network, it has forward method to calculate the output forward value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdYhflSGKAMS"
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        dropout_prob = 0.0\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer91 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer101 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer121 = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer131 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer14 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer15 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer16 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer151 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer161 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer152 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer162 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),nn.Dropout(p=dropout_prob))\n",
        "        self.layer17 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 6, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Identity())\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer91(out)\n",
        "        out = self.layer101(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = self.layer121(out)\n",
        "        out = self.layer131(out)\n",
        "        out = self.layer14(out)\n",
        "        out = self.layer15(out)\n",
        "        out = self.layer16(out)\n",
        "        out = self.layer151(out)\n",
        "        out = self.layer161(out)\n",
        "        out = self.layer152(out)\n",
        "        out = self.layer162(out)\n",
        "        out = self.layer17(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "       \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqsC-G-rr5lT"
      },
      "source": [
        "## Design of our input label:\n",
        "\n",
        "*  Marking point tuple represents the coordinates of a point and coordinates of its shape and the shape of the slot line.\n",
        "*   slot tuple reprents the two points, the angle between them and the shape of parking whether its parallel or perpendicular\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWID4l-er1Pm"
      },
      "source": [
        "\n",
        "MarkingPoint = namedtuple('MarkingPoint', ['x', 'y', 'direction_x' ,'direction_y' , 'shape'])\n",
        "Slot = namedtuple('Slot', ['p1', 'p2', 'angle','parking_shape'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DZcQc4I1ikD"
      },
      "source": [
        "## Dataset class\n",
        "\n",
        "*   initailization of images and its json files\n",
        "*   getitem function: used for indexing dataset and return dictionary containing image and the marking point\n",
        "* len function: return the length of available dataset\n",
        "* set function: update the values in json file\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8c1xlurG8fy"
      },
      "source": [
        "\n",
        "class ParkingSlotDataset(Dataset):\n",
        "    \"\"\"Parking slot dataset.\"\"\"\n",
        "    def __init__(self, root):\n",
        "        \n",
        "        super(ParkingSlotDataset, self).__init__()\n",
        "        self.root = root\n",
        "        self.sample_names = []\n",
        "        self.image_transform = ToTensor()\n",
        "        for file in os.listdir(root):\n",
        "            if file.endswith(\".json\"):\n",
        "                self.sample_names.append(os.path.splitext(file)[0])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        name = self.sample_names[index]\n",
        "        image = cv2.imread(f\"{self.root}/{name}.jpg\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image2 = cv2.medianBlur(image,9)\n",
        "        smoothed = cv2.GaussianBlur(image2, (9, 9), 10)\n",
        "        sharp = cv2.addWeighted(image2, 2, smoothed, -1, 0)\n",
        "        bilat = cv2.bilateralFilter(sharp,9,75,75)\n",
        "        image = bilat\n",
        "        image = self.image_transform(image)\n",
        "        marking_points = []\n",
        "        slots = []\n",
        "        \n",
        "        with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "            if not isinstance(json.load(file)['marks'][0],list):\n",
        "                with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "                    marking_points.append(MarkingPoint(*json.load(file)['marks']))\n",
        "            else:\n",
        "                with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "                    for label in np.array(json.load(file)['marks']):  \n",
        "                        marking_points.append(MarkingPoint(*label))\n",
        "                \n",
        "        with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "            if(len(json.load(file)['slots'])==0):\n",
        "                pass\n",
        "            else:\n",
        "                with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "                    if not isinstance(json.load(file)['slots'][0],list):\n",
        "                        with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "                            slots.append(Slot(*(json.load(file)['slots'])))\n",
        "                    else:\n",
        "                        with open((f\"{self.root}/{name}.json\"), ) as file:\n",
        "                            for label in json.load(file)['slots']:\n",
        "                                slots.append(Slot(*label))\n",
        "        return {'image': image,'marks': marking_points,'slots': slots}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_names)\n",
        "\n",
        "\n",
        "    def __set__(self,index,value):\n",
        "        # save file name then delete file then create another file with new data\n",
        "        name = self.sample_names[index]\n",
        "        in_image = value['image']\n",
        "        in_image = in_image.permute(1, 2, 0)\n",
        "        in_image = cv2.cvtColor(np.array(in_image), cv2.COLOR_RGB2BGR)\n",
        "        in_image = cv.convertScaleAbs(in_image, alpha=(255.0))\n",
        "        cv2.imwrite((f\"{self.root}/{name}.jpg\"), in_image)\n",
        "        in_json ={}\n",
        "        in_json = {'marks':value['marks'],'slots':value['slots']}\n",
        "        path = f\"{self.root}/{name}.json\"\n",
        "        json.dump(in_json, codecs.open(path, 'w', encoding='utf-8'),\n",
        "                  separators=(',', ':'), sort_keys=True) ### this saves the array in .json format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXc54YqONUj3"
      },
      "source": [
        "## Rescale\n",
        "Rescale the image in a sample to a given size.\n",
        "\n",
        "*   it take the desired size and return an resized image \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2tn6LFeNUj4"
      },
      "source": [
        "class Rescale(object):\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image =sample['image']\n",
        "        marking_points = sample['marks']\n",
        "        slots = sample['slots']\n",
        "\n",
        "        h, w = image.shape[1:3]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        \n",
        "        img = image.permute(1, 2, 0)\n",
        "        img = transform.resize(img, (new_h, new_w))\n",
        "        to_Tensor = ToTensor()\n",
        "        img = to_Tensor(img)\n",
        "        \n",
        "        mult = ([(new_h / h) ,(new_w / w) ,(new_h / h) ,(new_w / w)])\n",
        "        for i in range(len(marking_points)):\n",
        "            iterable_mp = list(marking_points[i][0:4])\n",
        "            for j in range(4):\n",
        "                iterable_mp[j] = (iterable_mp[j] * mult[j])\n",
        "            iterable_mp.append(marking_points[i][-1])    \n",
        "            marking_points[i] = MarkingPoint(*iterable_mp)    \n",
        "        return {'image': img,'marks': marking_points,'slots': slots}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT_8dkWpI2uD"
      },
      "source": [
        "##loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osLtZTbJPsDt",
        "outputId": "b949d4e3-3593-4657-e7e8-6825e6d5169e"
      },
      "source": [
        "dataset_path = r\"/content/drive/MyDrive/training_mix2\"\n",
        "park_dataset = ParkingSlotDataset(dataset_path)\n",
        "print(len(park_dataset.sample_names))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_cXaZCBNUj7"
      },
      "source": [
        "## - Dataset Preprocessing\n",
        "\n",
        "### + Image/Data rescaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpA6It9TNUj8"
      },
      "source": [
        "image_rescaler = Rescale((512, 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kirUGjkdiWz6"
      },
      "source": [
        "## Collate Function\n",
        "*  function to make all the labels having the maximun label size\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77JRX9ooNUj9"
      },
      "source": [
        "def collate_mod(data):\n",
        "    d={}\n",
        "\n",
        "    lengths_marks = []\n",
        "    lengths_slots = []\n",
        "    for i in range(len(data)):\n",
        "      \n",
        "      l1 =len(data[i]['marks'])\n",
        "      l2 =len(data[i]['slots'])\n",
        "      lengths_marks.append(l1)\n",
        "      lengths_slots.append(l2)\n",
        "\n",
        "    max_len_marks = max(lengths_marks)\n",
        "    max_len_slots = max(lengths_slots)\n",
        "\n",
        "    features_marks = torch.zeros(len(data),max_len_marks,5)\n",
        "    features_slots = torch.zeros(len(data),max_len_slots,4)\n",
        "    \n",
        "\n",
        "    dict_im = torch.empty(len(data),3,512,512)\n",
        "    for i in range(len(data)):\n",
        "        j = len(data[i]['slots'])\n",
        "        t =torch.zeros(max_len_slots-j,4)\n",
        "        features_slots[i] = torch.cat([(torch.Tensor(data[i]['slots'])), t])\n",
        "        k = len(data[i]['marks'])\n",
        "        t =torch.zeros(max_len_marks - k,5)\n",
        "        features_marks[i] = torch.cat([(torch.Tensor(data[i]['marks'])), t])\n",
        "\n",
        "        dict_im[i]=data[i]['image']\n",
        "\n",
        "    features_marks = features_marks.permute(1,2,0)\n",
        "    features_slots =features_slots.permute(1,2,0)\n",
        "    d= {'image' :dict_im, 'marks':features_marks,'slots':features_slots}\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlt9imFGNUj9",
        "outputId": "cfc8c91b-4733-4928-9efa-420d9057cc82"
      },
      "source": [
        "data_loader = DataLoader(park_dataset,\n",
        "                             batch_size=32, shuffle=True , num_workers=24,collate_fn=collate_mod)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix586SdfNUj_"
      },
      "source": [
        "## Grid locator Function\n",
        "\n",
        "*  To map the point coordinates to the grid range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0YFN6SrNUj_"
      },
      "source": [
        "def locate_grid_mult(x,y):\n",
        "    if np.sum(np.less(x,0)):\n",
        "        x[x<0] = 0\n",
        "    if np.sum(np.less(y,0)):\n",
        "        y[y<0] = 0\n",
        "    if np.sum(np.greater(x,512)):\n",
        "        x[x>512] = 512\n",
        "    if np.sum(np.greater(y,512)):\n",
        "        y[y>512] = 512\n",
        "    grid_x = np.divide(x,32).astype(int)\n",
        "    grid_y = np.divide(y,32).astype(int)\n",
        "    grid_x[grid_x == 16] = 15\n",
        "    grid_y[grid_y == 16] = 15\n",
        "    \n",
        "    return grid_x,grid_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62qhTuX7NUj_"
      },
      "source": [
        "## Convert Marking Point to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFn6l7awNUkA"
      },
      "source": [
        "def marking_to_tensor(marking_points):\n",
        "    output_tensor = torch.zeros((5,marking_points[0].shape[0])) #5_features,#_training\n",
        "    for i in range(5):\n",
        "        output_tensor[i] = marking_points[i]\n",
        "    return output_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UySlhTkSNUkA"
      },
      "source": [
        "## Complete 6x16x16 label Vector\n",
        "\n",
        "*   creating labels of dataset to be trained\n",
        "*   labels represent: confiednce , x (from -16 to 16) , y (from -16 to 16) , cos(theta) , sin(theta) , type of marking point \n",
        "* Note : Some values are mapped to be in the same range of values as the others\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9saVlWJNUkA"
      },
      "source": [
        "def complete_marking_vector_label_mult(training_examples):\n",
        "    values = np.arange(16,512,32);\n",
        "    number_of_trainig_examples = training_examples['image'].shape[0]\n",
        "    label_vector = np.zeros((number_of_trainig_examples,6,16,16)).astype(np.float64)\n",
        "\n",
        "    label_vector[:,1:3,:,:] = (label_vector[:,1:3,:,:] + 1) * values\n",
        "    label_vector[:,3:5,:,:] = (label_vector[:,3:5,:,:] + 1) * values\n",
        "    label_vector[:,5,:,:] = label_vector[:,5,:,:] + 0.5\n",
        "    \n",
        "    for i in range(len(training_examples['marks'])):\n",
        "        try:\n",
        "          grid_x , grid_y = locate_grid_mult(np.array(training_examples['marks'][i][0]),\n",
        "                                            np.array(training_examples['marks'][i][1]))\n",
        "          for j in range(number_of_trainig_examples):\n",
        "            label_vector[j,1:,grid_x[j],grid_y[j]] = (marking_to_tensor(training_examples['marks'][i]))[:,j]\n",
        "            label_vector[j,0,grid_x[j],grid_y[j]] = (100)\n",
        "        except:\n",
        "          print(\"Problem at :\" ,i,\"\\n\\n\",training_examples[i])\n",
        "          \n",
        "    label_vector[:,5,:,:] = label_vector[:,5,:,:] * 100\n",
        "    \n",
        "    x_old = np.copy(label_vector[:,1,:,:])\n",
        "    y_old = np.copy(label_vector[:,2,:,:])\n",
        "    x_val = (np.copy(label_vector[:,1,:,:]) % 32) - 16\n",
        "    y_val = (np.copy(label_vector[:,2,:,:]) % 32) - 16\n",
        "    dir_x = np.copy(label_vector[:,3,:,:]) - (x_old - x_val)\n",
        "    dir_y = np.copy(label_vector[:,4,:,:]) - (y_old - y_val)\n",
        "\n",
        "    marking_direction =  (calc_angle_2([x_val,y_val],[dir_x,dir_y]))\n",
        "    cos_theta = np.cos(marking_direction) * 16 # just to be in same range (dont forget to divide)\n",
        "    sin_theta = np.sin(marking_direction) * 16 # just to be in same range (dont forget to divide)\n",
        "    \n",
        "    label_vector[:,1,:,:] = (label_vector[:,1,:,:] % 32) - 16\n",
        "    label_vector[:,2,:,:] = (label_vector[:,2,:,:] % 32) - 16\n",
        "    label_vector[:,3,:,:] = np.copy(cos_theta) \n",
        "    label_vector[:,4,:,:] = np.copy(sin_theta) \n",
        "\n",
        "    return torch.tensor(label_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoDdB2iFTA0s"
      },
      "source": [
        "# function to calculate angle between two points\n",
        "def calc_angle_2(p1,p2):\n",
        "  y_diff = p2[1]- p1[1]\n",
        "  x_diff = p2[0] - p1[0]\n",
        "  theta = np.zeros_like(x_diff)\n",
        "  theta = np.arctan2(y_diff,x_diff) \n",
        "\n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNsJOkR-NUkA"
      },
      "source": [
        "## Image Visualizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nJEmuR7NUkB"
      },
      "source": [
        "def image_visualizer(parking_image):\n",
        "    plt.imshow(parking_image['image'].permute(1, 2, 0))\n",
        "    for i in range(len(parking_image['marks'])):\n",
        "        plt.plot([parking_image['marks'][i][0],parking_image['marks'][i][2]],[parking_image['marks'][i][1],parking_image['marks'][i][3]],'o')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjEB7GwqihH6"
      },
      "source": [
        "## Evaluation\n",
        "* Compare output with ground truth to extract TP , TN , FP , FN \n",
        "* Notice that  :\n",
        "\n",
        "1.   True positive is considered to be an existing marking point with confidence more than a certain threhold , and x , y , sin , cos , shape difference between output and ground truth less than a certain threhold \n",
        "2.   True negative is considered to be a non-marking point with confidence less than a certain threhold\n",
        "3. False postive is a marking point that the output failed in one or more critrion of a True postive\n",
        "4. False negative is a non-marking point which have a confidence more than a certain threhold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo7j_r5dWb1h"
      },
      "source": [
        "def eval(output, label):\n",
        "  \n",
        "    conf_flag = (label[:,0,:,:] == 100)\n",
        "    not_conf_flag = (label[:,0,:,:] == 0)\n",
        "    out = output.permute(0,2,3,1)\n",
        "    label_p = label.permute(0,2,3,1)\n",
        "    threhold_conf = 70\n",
        "    threhold_coordinates = 10\n",
        "    therhold_direction = 10\n",
        "\n",
        "    true_negative = torch.sum(torch.bitwise_not(torch.bitwise_xor((out[not_conf_flag][:,0] < threhold_conf),label_p[not_conf_flag][:,0] == 0)).type(torch.float)).item() # sum\n",
        "    \n",
        "    false_negative = torch.sum((torch.bitwise_xor((out[not_conf_flag][:,0] < threhold_conf),label_p[not_conf_flag][:,0] == 0)).type(torch.float)).item()\n",
        "\n",
        "\n",
        "    confidence_ones = torch.bitwise_not(torch.bitwise_xor((out[conf_flag][:,0] >= threhold_conf),label_p[conf_flag][:,0]==100))\n",
        "    x_val = (torch.abs(out[conf_flag][:,1] - label_p[conf_flag][:,1]) < threhold_coordinates)\n",
        "    y_val = (torch.abs(out[conf_flag][:,2] - label_p[conf_flag][:,2]) < threhold_coordinates)\n",
        "    x_dir_val = (torch.abs(out[conf_flag][:,3] - label_p[conf_flag][:,3]) < therhold_direction)\n",
        "    y_dir_val = (torch.abs(out[conf_flag][:,4] - label_p[conf_flag][:,4]) < therhold_direction)\n",
        "\n",
        "    shape_val = torch.bitwise_not(torch.bitwise_xor((out[conf_flag][:,5] >= 45),label_p[conf_flag][:,5]==100))\n",
        "\n",
        "    \n",
        "    true_positive = torch.sum(torch.bitwise_and(confidence_ones,torch.bitwise_and\n",
        "                                            (x_val,torch.bitwise_and(y_val,torch.bitwise_and(x_dir_val,torch.bitwise_and(y_dir_val,shape_val))))).type(torch.float)).item() # sum\n",
        "\n",
        "    false_positive = ((label_p[conf_flag][:,0]).shape[0]) - true_positive\n",
        "\n",
        "\n",
        "    accuracy = (true_negative + true_positive)/(true_negative + false_negative + true_positive + false_positive) if (true_negative + false_negative + true_positive + false_positive) != 0 else 0\n",
        "    precision = true_positive/(true_positive + false_positive ) if (true_positive + false_positive ) != 0 else 0\n",
        "    recall = true_positive/(true_positive + false_negative ) if (true_positive + false_negative ) != 0 else 0\n",
        "    f1_score = 2*(recall * precision) / (recall + precision ) if (recall + precision ) != 0 else 0\n",
        "\n",
        "    return f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoSxddTKil_I"
      },
      "source": [
        "## Loss Function\n",
        "it calculates the loss with two differnt weights according to the confidence:\n",
        "\n",
        "if it is 100 then weight is 1 for all values (confidence,x,y,x_direction,y_direction,shape)\n",
        "\n",
        "else weight is 1 for confidence and zero for the rest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q2KjNnhXp2P"
      },
      "source": [
        "def my_loss(output, label):\n",
        "  conf_flag = (label[:,0,:,:] == 100)\n",
        "  not_conf_flag = (label[:,0,:,:] == 0)\n",
        "  out = output.permute(0,2,3,1)\n",
        "  la = label.permute(0,2,3,1)\n",
        "  Loss1 = torch.mean((out[conf_flag] - la[conf_flag])**2)     #all\n",
        "  Loss2 = torch.mean((out[not_conf_flag][:,0] - la[not_conf_flag][:,0])**2)  # confidence\n",
        "  # print(\"\\n\\n\",'Loss All:',(torch.abs(Loss1)).item(),\"\\n\",\"Loss Confidence:\",(torch.abs(Loss2)).item() ,\"\\n\\n\")  # prints the loss details\n",
        "  return torch.abs(Loss1) + torch.abs(Loss2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnQhkxjr0Lb0"
      },
      "source": [
        "### Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHCcGQ42NUkB"
      },
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5000  \n",
        "learning_rate = 0.001\n",
        "model = ConvNet().to(device)\n",
        "checkpoint = torch.load(r'/content/drive/MyDrive/model1_checkpoint_15000_rel_lr0.05_img_enh_1_7')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min',factor=0.5, patience=200, cooldown=50, min_lr=0.00001, verbose=False)\n",
        "model = model.train();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv9_pHUqiqa4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "e0lhk0UxNUkC",
        "outputId": "d93e11b0-e31e-4836-8c9c-6d81db5edbc1"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "total_step = len(data_loader)\n",
        "graph_itrator = 0\n",
        "graph_itrator_2 = 0\n",
        "batch_loss = 0\n",
        "actual_batch_size = 512\n",
        "actual_batch_factor = actual_batch_size/32\n",
        "number_of_batches = math.ceil(len(park_dataset.sample_names)/32)\n",
        "myloss = checkpoint['loss']\n",
        "model = model.train();\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  L = 0\n",
        "  start_load = timeit.default_timer()\n",
        "  for i_batch , train_batch in enumerate(data_loader):\n",
        "    start_batch = timeit.default_timer()  \n",
        "    print(\"loading time is:\",start_batch - start_load) \n",
        "    start_load = start_batch\n",
        "    images = train_batch['image'].to(device)\n",
        "    labels = complete_marking_vector_label_mult(train_batch).to(device)\n",
        "\n",
        "    # Forward pass        \n",
        "    outputs = model(images).to(device)\n",
        "    outputs = outputs.reshape((-1,6,16,16))      \n",
        "    myloss = my_loss(outputs.float(), labels.float())\n",
        "    \n",
        "    # Backward and optimize        \n",
        "    myloss.backward()\n",
        "\n",
        "    if graph_itrator % actual_batch_factor == 0:\n",
        "      scheduler.step(batch_loss)        \n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      for g in optimizer.param_groups:\n",
        "          lr = g['lr']\n",
        "    \n",
        "    batch_loss += myloss.item()\n",
        "    # if graph_itrator % 30 == 0:  \n",
        "    #   torch.save({\n",
        "    #           'i_batch': i_batch,\n",
        "    #           'model_state_dict': model.state_dict(),\n",
        "    #           'optimizer_state_dict': optimizer.state_dict(),\n",
        "    #           'loss': myloss\n",
        "    #           }, r'/content/drive/MyDrive/model1_checkpoint_15000_rel_lr0.05_img_enh_1_8')\n",
        "      \n",
        "    print(\"epoch: \",epoch,\" batch: \",i_batch,\"lr:\",lr,\"graph_itrator:\",graph_itrator)\n",
        "    stop_batch = timeit.default_timer()\n",
        "    L += myloss.item()\n",
        "    print('Batch Time: ', stop_batch - start_batch)\n",
        "    time = stop_batch - start\n",
        "    hrs = int((time)/(60*60))\n",
        "    mins = int((time - ((60*60)*hrs))/60)\n",
        "    print('Overall Time: ', hrs,\"hrs , \",mins,\"mins , \",(time)%60,\"secs\")\n",
        "    \n",
        "    \n",
        "    if graph_itrator % actual_batch_factor == 0:\n",
        "      plt.plot([graph_itrator_2], [batch_loss/actual_batch_factor],'.r')\n",
        "      batch_loss = 0\n",
        "      graph_itrator_2 +=1 \n",
        "    plt.grid(b=True)\n",
        "    graph_itrator +=1 \n",
        "    display.clear_output(wait=True)\n",
        "    display.display(pl.gcf())     \n",
        "  print(\"Averged Total Loss = \",L/number_of_batches) \n",
        "    \n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2df5BcV3Xnv6e7Z4SDmDUekkE2aGUHwhY2a1kWSqYSqBE2/gVaO3H+WNa1MgisiGCDsQoFZStZp8haSYixiOV4JUeSmSotYrdEYmwQRhaaQNAUtn4iTxzCj9JqDZYdFBRFqfJoftz94747777b9/3q7tfdr+f7qeqa6dfvxz33vXfeeeece64opUAIIaR8VDrdAEIIIY1BBU4IISWFCpwQQkoKFTghhJQUKnBCCCkpVOCEEFJSUhW4iLxGRJ4VkeMiMiEifxQsv1xEvisiPxSRL4lIf/HNJYQQYpC0PHAREQCvVUqdF5E+AH8H4BMA7gPwZaXUbhH5nwCOK6UeTdrXG97wBrVkyZKGGvpv//ZveO1rX9vQtmWDsvYm80lWYH7JW7Sshw8f/plS6hfrflBKZf4A+AUARwD8KoCfAagFy4cBPJ22/bXXXqsa5cCBAw1vWzYoa28yn2RVan7JW7SsAA4pj07N5AMXkaqIHAPwCoB9AH4E4KxSajpY5UUAlzX1iCGEEJKLVBdKZGWRiwH8NYA/APC4UuotwfI3A9irlLrKs81aAGsBYGho6Nrdu3c31NDz589j4cKFDW1bNihrbzKfZAXml7xFy7py5crDSqnl7vJanp0opc6KyAFol8nFIlILrPA3AfhJzDbbAGwDgOXLl6uRkZG8bQcAjI2NodFtywZl7U3mk6zA/JK3U7JmyUL5xcDyhohcBOC9AF4AcADAbwer3QngiaIaSQghpJ4sFvgiAF8QkSq0wv/fSqmnROTvAewWkT8GcBTA9gLbSQghxCFVgSulvgfgGs/yHwNYUUSjCCGEpMORmGVmfBzYtEn/JYTMO3IFMUkXMT4OXHcdcOEC0N8P7N8PDA93ulWEkDZCC9ylLFbt2JhW3jMz+u/YWKdbRAhpM7TAbcpk1Y6M6Daats6TdC1CSAgtcJsyWbXDw/oB85nPtOdBU5Y3E0LmEbTAbcpm1Q4P+xX3+Lh++IyMtEaxl+nNhJB5BBW4jbFqW6n82k0Rytb3ZlLGviGkx6ACd4mzastCEcq2bG8mhMwTqMB7jSKUbS+8mRDSg1CB9xpFKdssbyat9r0TQhKhAu9FOuEGYqCTkLbDNELSGsqUgklIj0AFTlqD8b1Xqwx0EtImesuFUoQPln7dbDDQSUjb6R0F3qgPNklB06+bj7KnYBJSMnrHhdKID9Yo6D/4A/3XHSZOvy4hpIvpHQXeiA82TUEn7ZO1QQghHaZcLpQkd0cjPti0QS9x+0xzrdBvTghpA6VR4AMTE8CnPpXsj87rg82i9H37TBquTr85IaRNlEaBX3zsWDEFlRoJvCVZ7iz8RAhpE6VR4GeXLu2egkpJljsLPxFC2kRpFDgA4M479d/Vq+Ot2nb5n32Wuzn25s3AmTP0gRNCCqUcCnx8HFevXw9MT2urdvXq2PVw3XXA5CRQqQCPPAKsXdu2NtL3TQhpJ+VIIxwbQ2VqKj0fe2xMK+/ZWa3s7747muZXZOofc8YJIW2mHBb4yAhm+/pQNRZ4nF95ZERb3rOz+vvMTBhELNpCLovvmymO5YXnjjiUQ4EPD+P4gw9i2blzyRfv8LB2m9x9t1beCxaEitS2kCcngfvv159W1svu9log3eDmaZcS6jVl1w3njnQd5VDgAM5deaW+GY0bxFbM9k26di3wjnfULzcWsnGxPPMM8O1vt/ZG6PZaIJ1OcfQpoXYdp5vPSxY6fe5IV5KqwEXkzQBGAQwBUAC2KaU+LyL3A7gLwD8Fq/6+UuprRTUUQDRIKRK6S9yb1Pw1fmijWPfv11b3M8/o7ebbjdBpN0+7lFAvKrtOnzvSlWSxwKcBrFdKHRGR1wE4LCL7gt8eUkr9eXHNc7CDlIC+QYHsoyGHh7UC//a3y3sjNOMa6LSbx6eEJifbc5yy0+lzR7qSVAWulHoJwEvB//8qIi8AuKzohnlxg5SAtsR9oyGNop+cjCr3Mt8IrXANdNLN4+v7IrJ1ynyOk+h2Fx1pO6KUyr6yyBIA3wJwFYD7AHwQwDkAh6Ct9J97tlkLYC0ADA0NXbt79+6GGnr+/HksXLgQl2/disVf+hIAYLZWw+mbbsLLN96ofeQBi558Er/yuc/Nff/H++7DS6tWefc7MDGBi48d0yM9gbn/7f21GyOrzcDEBJY8/jhef/gwRCnMVio4uWYNTt1xR6FtsfuniD7xydqrzCdZgfklb9Gyrly58rBSanndD0qpTB8ACwEcBvBbwfchAFXoXPL/AWBH2j6uvfZa1SgHDhxQ6uBBpS66SKlKRalaTamtW8MVDh5U6oEHwr+VilKA/vvAA/6d2vurVpXq69N/L7pI/9YhDhw4EF1gt9PI1I42muMW2Cd1sqa1x5zjEpJL1h5gPslbtKwADimPTs2UhSIifQD2ANillPpyoPhftn5/DMBTTTxgsmGCU7Oz2nVy5oxe7roWNm/WKYRpPtCsPvVOY8tdqQDXX9/aFMi043ZDMLAXM0sIaZIsWSgCYDuAF5RSn7OWL1LaPw4Avwng+WKaaBEXnHIVzZkzoQ90cDCajeLuL4tPvdO4ct9+u1+mVuc+ZwkGtivfupseJoR0CVks8F8H8F8BnBCRY8Gy3wfwARFZCp1aeBLA7xTSQpu44JRP0ZjfjNVWrQJr1kQLYbkDf2q1+nWKIo/is+UeHATuvbfeEi3CQk0LBrbTKu7FzBJCmiRLFsrfARDPT8XmfMfhi8THKRrbapuZAbZuBb7whaiiiRv40wrilHQjis/IvWmT3xItykK1+9uVZ3QUePVVQKnGjjk+jsW7dml3V56HWC9llhDSBKUZiZmKT7GPjGjL2/i2lapPK4zbtlmSlHQzyjbOEi3aQvXFGXbs0H0K6LeXPMcM9nf5q68Cjz+erXIk0+gIiVCOaoSNMjysXSI21Wp0SH5RkxL7aq+YY7mTJQ8OZm+LsUQ/85n60ae+5UXIc+ECsGdP+GAUAT70oXzHDALIopS/ciQhJJXescDjWL1au01MjfAtW/TykRFgagro66u3gFsRmEurvZLk026UIi1UWx4RYOnS6IjWuBrtPsbHgVOnABEoBP45t3IkXSWEpNL7CtznO/3oR7XiAfTf0dH8kxKnKZm02itpPm0f4+O6rTt3hpNb5LG2zfZAfaA2izybN4cB34cfbmzmIbt/RaAqFa3ATeVIpgsSkpneUOBZlI+x7DZtAk6fjt9XFv+0rWR82S32cdNqr2StD2KOaYKGQD7/+fi43rd5cO3cCRw4EM1gSZvJ6MwZ/SAyD6MzZ4CNG5OPmRRYrlbx0vveh8uGh8N18jzQCJnnlFeBG+UQl1bnrmtbrtWqdp34pmiLCwbayihLdoshLXsia30Qc0yjvO189aRsF7vNU1Phb24Gi3H1zM5qK/sd7/AHhbMGSuNKx546pQOeANDfj5dvvBGXfexjjR2DkHlOORW48xoesQp9/mzXcp2dBW69FVixIqr04iYl9mVg9PeH+7TT6IBQadr/J1mqTqqeN7VucFBbx0pF89WBqPV8333AxRfXP9g2b9YPLWOBuxkscTMZue3MmsrnvsmMjuqHnHlrWbUKeOMb/X3BdMHeh3GOllBOBW4rh0pFK4S4EZTGurSLdikF7N0LbNgQKugk37KbUbJnj1aIR49GtxkcjLpWRPL5qk1q3eQksGtXdJDOvfeG8j78cOji2LQpaj3/2Z/pdYxCtt0dY2OhD/yaa6KjOeNmMnLJGih1LWkg7EOlgK9+FZidxdW1GrBsWfFpnaR7YJyjZZRTgdvKoVoFbrlFW3O+wFyQ7VDH9HSowNJ8y0kZJatX+10rxpp1rfPRUe2D97U32F7ctwmzX7cGjGmbWw5gdlYf10x6YY9OjRu1aQY0GQV/4kQ+C8m1qIwlbT8wzDkTmesjUYp+7vlGUYPO5iHlVOC2cti+HXjiiXpftutmqVZDxWYrtSTfsns8X0bJxo3Ri89+sNgW+OBgNIgIRAOJwNyDYnZyEpWsg3Rs63l6OlTcxrVTqQD33ON9UHhvIJNyaQpnLVgQtZB8r75JFpVxmxg3zpkzEfeOyjsAiJQf1wA7dUpfQ1TiuSmnAgfCodwmMDc5GU0HdLIdcNddwOLFWnm4qW/2xZQlo8TkQg8O1q+zebN+qFx6KXDzzeGx3CAiUK88gwfFyR07cIUZgPTRj+q/SSl7djmAwUHt4tm3Tyvw2VngoYeAX/7lcPu4B4Jt6QP676uvhv0ap6jjHgjucjtrJWjv8YEBLCtiFCz9q92LbYDt3Ak89lh8EgBJpLwKPA47O8VWUnEFqpKCZj63gJ0Lfe+90WyN8XFt7Rore+/eqIVtBxEBv89+eBhnjxwJ3y6M0l+wAPiLv4hmqLhtM8d5xzuAb35TW+RAONLRnj80qSiYXWJXKX2TGVeRG5j09XXWN4fhYZzzZdz4+j4rjfhXqfDbj3nAT0/TldIE5Vbgq1frehxmROU119Rni2QZaOILmsUpAjcX2r7oklL1AG3dmxx0nw88OO7V69dH3TqAVqpGCVer+jfjnrEfEkYeOyhZqYR+eWNRP/pocpbJs89q15Q5jlFw9tuKHcD19XWjGSXNBLny+lfnS0CtGx9STBltmnIrcPMU9wURsww08WEu9FOn/PNqJl10IyP+VL08SmJsDJWpqajyBsKiXObhYX53XUcG161i3gxsizpt0NPevXqbSkX3BxAq5FOn9KtvWl83klHSTJArr1IoIqCWR1m2Q7F260OKKaNNU14Fbl/4tuKwb15TJCpPJoWbXw7ov4OD9Xnig4NaeY6OhgrRTtUzy7KMLrRcP6pa1dkZtRrwvvdpa/2aa8K8biAsJJWErTyPHtUDjmyLOikwCYSB0Kkpve1f/ZW27Ddu1NvYed1ZA1FZFFYzlllepdCsFejKk0dZtkKxZunPbs76YMpoc/jmWSvq0/ScmIakuRrNvIlbt+afz/GBB/T6gFIiRn3pOSjXrYvub+tWpfr7w3UWLNDLfHM2+tprz+948GC4r0pFzVSr+vj9/fGy9ff714kjrs/iltt9YX/6+qLbrlunZU87FzHnJHYuwXbOf9nosXx9Z/dbtRqZj7VO1oR1Gz5+M+u1GM6J2TrQzJyY3cDAxERYzyPJojBP9EZqarg+XpMGWK0CR46ELpULF3Smh+3vtn3UrjVlgp979ujp0ICo5XXjjaFlPTsbzp7hjoh0A5VZAq/297RJL+x+8gU03TYlBaLs+iomJdEdXJR0TtppmTV6LF/f5bHom7X+s1rW3eKqKMpd1I3+/TZRDgVuAnt2wCzNVdLIzWFf6IOD2u1w+rT2BR86FCqi/v5wXkqjeG0ftXszmZGUFy7oNMQbb4zOZPPTn9a3JW1uziyB182b6+vEuH5qt5/svjR9cfasTkU0ozTtdfKkJJp+MrINDvrLBmS9ITt94/pkz6Msm1Wsea7xPA+pIvq1KD98t/r320Q5FLgJ7NnDwtPmiGz05jDrmYsCiAYNly/XinF4ODpy0fZRuzeTbSlNTgJPPhmdyebDH9YPi8CiV9Uq5K676oe7+7BLxAJRi2zPnuhx778/nM3eZ5n7+tIo/Ntui18nS0qiGRTkDObxlg3IWs63qBs3qwKLu8byKMtm3jSKsKyL6tei/PDd7N9vA+VQ4CMjmO3rQ9VY4Hbuc5KrJO7mSLtBx8bqXQeG48fD/939x7k1bEvJDo6amWycYezHrroKy5YtS7+Rtm0Dfvd3w4BmX1+k0h9uvz0ceGSXAIizzLP0pb2OSUn0Tebgvs0YpW0PbLpglQ0wOeXPPpttns1m5+OMI68C63QQrtXHL0ohFpUyON9TEX2O8aI+zQQxD2/Zkj1AmESW9bdurQ/emY+IDtzlJUdw9cCBA+kBroMHlarV/G2z++ngQaVWrAiDstWqUjfcEA1QrlgRBlMvukgHbWs13VafHHbwtq8vPohpb+MGO4N+mKlU9P4WLNDHteVZsCB+f1kDyHlx+93tzyYoRVCvhQHPOnmLCky3M+AdA4OYKZy78kr/0zXva2QWC+PMmfoCUQal9AhJID6XGvCP4vQFIIGo/96Uk33nO5PrRYyN1bevUtFuF7N/w7FjUZeN8d8by/3ZZ4F3vQv4y79MHmkK6P/XrImmJJp+8fXntm3ROi1AxA12cscOXFGr6ZxyV56bb45/Q7Ln47z55vSa8FlJGqzUC/7VrDNJpd1PjfjJi3pb6fRbUCfxafWiPi1NI2z0iZvFwrDX6e/XVthtt0VTC0X8KYFZj+FbL7BKZyuV8Pttt+nfzTL3GJVK9GOsWbPPdeuiqZHr1oVWuS9F0F4/LrXt4EF9DJFkCzzuLcFa78CBA6Esbnvi3nTcfsvS5jyY89ni/XbcAm+VdZ1xPx2Xt43QAs9Ks0EW1zdrW6q2ReFaIePjwNNP10/iYE9UYNrjBi3t4KGN+zYQBB3n/MJHjwJPPRVam/aIULuN9qhIk9po2nf6dDgRxIIFYbmBV1+t7xtznCw+RWNNi+gaLb6SBe5bgikq5r65mDRL158fN1Gye36A6Dmw25xltiL3vJj+tQcrtcq/2snMmVb5t+d54LCbKJ8Cb8XF42aaxE2+4CoZu4KaWReIzwWOm5He4AZggqDj7OQkKib33B5xWa16C0LVjYq089f37g3roZgMEDOk3kZEK/jVq6M1zpNcGErpv75h9KYWe1+ffqhUKvFzbQLRGuciOjMnT/DQ99of97DPagTkcc9lUMwDExPApz7V2gwPu3hbWt2fVgX82hU47HSaaBnwmeVFfVriQmnVa6A76tIO8qW9KrujKONGON5wQxiYiwuIedwvL65aFQ3qicQHFePaFOcCsF0vZpSpcRPFuZN8bU46B1u3atdK2r5VAefVbm9cILjZEZC+Y2Zo+48+8pFijmufy7S+a1XAL20/Bw9qeZs5j3lHGzfSzhbRKRdK+RS4Uq05Ka6fOy2TIm1faRkyOY4RudErFf0gaKW/3x3insdH7z4kfPu0/d6VSqKimvOBp7Unyzn3tdf46u2MllYPLc/4QDi8ZUt6lk+jxzWfVjwYmiXo39ksD5Q4brstWzwkQzvaUUKgaxU4gDcDOADg7wFMAPhEsPwSAPsA/CD4+/q0fbVMgbcKn9VaVIpTUkDMOfbcjd6KC68ZuWwFUaloqzouWGna6yoUu3aKh8NbtqRbWllvRF8KYNy+W3m+8wT17LeTtAB31gdWHgu8HbSixot7HbkKPEv/tPpNK4FuDmJOA1ivlDoiIq8DcFhE9gH4IID9Sqk/EZFPA/g0gN9roXcnP3l9Zj4/d6uPnRYQ8/hjz115ZetG2DWSYuWbFMOax7Iu9mDHJWyqVWDLlsTjDz39dDji1QSF04K9cXEPNwXwyJEwfdGu4WLLlzbSNQt5fOVJ9eTtdmVJi/QNlmrmemmVzzk4D5GpAfPse2wsGqOpVuOnS0zqn/kwyMen1ZM+AJ4A8F4A3wewKFi2CMD307Yt1AJv4+tSrmOnWfkeK6Gj6VdxbpOkAUhmGzfNMsNr74urVqW/KruuqASfujp4MBw05LNMO2i1RlImk6pC1mrpsZNW0+r7x/aB5923fY58rqY8lnWnfOAtPi5akUYoIksAXAPguwCGlFIvBT+dBjAUs81aAGsBYGhoCGN22l4Ozp8/n7jt4l27cPnkJGR2FrOTkzi5YwdOTU42dKy8xB17YGICV69fj8rUFGb7+nD8wQdxbng4TAcEMDAwgKtrNYhSULUajg8MpMraVlmeew6n7rhDt/Wzn8XFx47h7NKlOGfJYH4bevppLPr614GZGai+Phy/6qq5KdMGJibCba+8cm672rvfjUVf/zpkehqqVsMxaxsbe/+ybRtmd+7U/Wnta06G6WlcPjWlZRDB2WXLcPKDH8S5ycmIfAqIvV587Y2TIQ2zXe1tb8PY8uXefoz0u8hc9UZVqUC2b4fMzITXUMqxG2lnnvsn6/7P33orTjl97u47bl+mj6YGBtD33HM4OzUVngfPPRM7NR+grXPnes1DFnnte9Z73+e4XnLh0+q+D4CFAA4D+K3g+1nn95+n7WPeWeBZLQXnad0RC9wOJDbTjzmzViJBzLTgZZ7+THtbiLPAbQverd+et1+cfU3HlQbwtdm8+eQdTJRmvfrWz3Pec/TD3HUc5/dP21fWN9siyRPfMBTge0czFriI9AHYA2CXUurLweKXRWSRUuolEVkE4JUWP1vyUURltmaPneaDsysJJg3LLxpfGdpG/ak+n7vPhx0sHxgYAD72sfiiY2670vrTnAPfQCz3N9dvbI5nBmsB0fZmGZzltt3alyiVv2Z33sFEY2Ph+IPZWV3GwC2HkNS/aefdPpemmFlafvy990bHIvhiJ77YRtLvRQ2fd331jYw7aaPvPVWBi4gA2A7gBaXU56yfvgLgTgB/Evx9opAW5qGTNRF8x056qJjJKUwAb+fO+smJ24V7kTYyl2gSvprjgeK4ulYDli2LHzDktitOMSeVwrUnlzADinzy2RUOgfqa7P39+vfZWWDfvnBwlmmrfY5N2619qb6+/DW78xomIyPROj7upCA2jZz3wcHwf6WS51e1jzE7q/vTHrCVpujaHYT0BUcbaUM7jUmfWW5/APwGAAXgewCOBZ9bAAwC2A+dRvgMgEvS9tV1aYSd5IEH6oN+watW22Vth/spxhUyk5QnnucV2w78ubnz69alpzYePFhfZdENlm7dGq2Y6Jtqz+ceCAKvh7dsyd9XeTDbbdiQPVWxkeCifd0muAgSg7ZZZW2Xq0SpeNdHhja+uGpVcnC9SdCoC0Up9XdAOMuXw3VNP0F6gUbSr0ZG/DPYd4J2WAyudRlYNapWS551KKldtsVcqeh0M6C+9vmOHdHtfFbp6GhYR8YM5X/0UX1uTbVI23oEwuP5XrF9KX5ZaLTWj7vdli3p7pC8593zVpFpJqCkY9hptr4JyNvxVu1Lm7XlSmpD8CZ9aYfepMtXC6XbaPSGM/61bvCBm/a06/jWTX18YADL8tQ8MYyPa8VslElfny6qtWePVt723KV2frqp+WJPCwdE99Xfr8+Hz0e8YEHoitmyRfuX7To0puwvUOfaSXQXGbL4XH0Gg88dYibOMP2YpX+TjBE3z37NmmzXbdq1ZUoOmyn77Hsor3HUyPrNxH/GxoCpqdDCbXNxLyrwZmkkyGHopM++0wSyJ6Z/JTE2Fq0Jbs9s9O1v1xUIiygdM/2dUcTvf3/9voaH62cocn3wph2bN+vKkTt36qqQO3aEBcWAuSn56oKYtrIx+4qzAg1xBkNCnKHOsIgrgJVmjBTxpjY+roPYpq/sipt5jaNG1r///uhk5XnjP8GbtLpwQSvxNr9JU4E3y3wY7ZWXdlSRGxwMy+SaaeTMhBeuknGnutu0KZqp8eST0anozKg/37m1X/ltZXHnndoFY/YJ1Fd8tKtJ2tu71TBdKzBu3lM7C8SVO86wsAO69lylbhnkOGOkGaMj7s3BLTlsP9DyvI2465tp+nzXoa8f0u5fX/uDN+mfbtqEyy67rP1v0j7HeFGfng1itjjQ0tWyppG11kdAJlnd/jXHEAnrr+SpWnfwYH3BrbjRjnHn1g14ucWXKpW6IPWLq1aF+3Mn2jDruiNYfcHVvr7we9K0c2ljE9xApDlWsxUAA+oK0Pny0+3lph+T8sTdkc1xxcvciUbcQmlunZ+0gnEp13XXFrNq5adnFXiLKa2sPsWYMogh9wAtt9ph1ll8XNIeNHGK2870sB8c69bVz+lpygAHbf+H++7zV6fs749Xyr5sJXuO06SSBUmDquLKDPiqN2bpFw91g1vs/rEzgeIGT7nHc68Fd5CTXbzMzGIVV4gtTwZOhuu6m4tZEZKNpNfhZvZpvxZv3x76SwHterBdFUeOROcOjcP4y20ftB3UTJoIwrx2G5TSfvUFC6J55OaWD2Yh6tuxI1r06667gMWL9TFHR6PzjBp3gZutVKvpDJljx8KMkLhc7LS8ctcHvmlTWPzLboMhq485cDUMDAyE/enmp09Ph4OhAODHPw5dUG42jzmGHZN49VU925Tt4jp9Wu/D9LtxTfkKsW3cmN2fb8dbgNZc1y2CCpy0jpGR+iyNZv2Btq+7WtXBQkO1CqxfD3z+8/qYAHDokFYyWbKBkvzZvpGjdsDLZnpat+vOO7USefLJ8IafndXKCcDZpUujCsdVunEjLm+5BfjKV8IHw9GjetkTT+hlU1OtCZ67WSbuRNp22qYzotYXCI1k3QwP6wFU9gTXzzyjtxUJlXeSL3pkRLfLzAa1d284nd/gIHDPPfVZSeY3e5CXnYGUJWA5OBg1Ej75yfTgqBucLioe5DPLi/rQhZKNUsuaMx6QKKvrNzUTPLuug4MH62c/ylN/wldH3HXb2G4H26Xhe0U3A2nMeoGb4vCWLel1X8wE2uvWhcd1j2dcM/ayZieHcNvg+o/Xrat38/jqp6QN0nLPle3/j/NF2322bp3ffeTOsBVXP9xtc5ZJRGz3mJHJtCUYvOOdWarZiWIsQB94eaCsAfbN6lOsPt9uI4WP0oJlvoDX1q3hA8U3MtHzUPnRRz6S3BluwNL247of+5gZYg2xx7OU0By+iTx8pYJ9D74sxbvyKDn3Ib5hQ/ThZY4Rd/7dc9/IJCVuG7dujZ6nBQvCUbbNTNWYQJwCpwuFdCfuQJ1aLXnC5bgc5SwDNcy2dqpezMhR9PeHRazOnNHuEtNGe2Ti8LBez8pBX/Dyy8n++WBQyBwzM9oVIKJdB7fcot0GZsJqO/Uwb/pbUi2ekRHd36Z+iXFZGBlf8xp9Hk6ciLq3du7U7RcBVq3C8euv9w/Scs+Vkd1t39iYduPYKZ8PPhh1Zxj3ke3TNhN1nDgRzfd/5JGom8jnGzdtsY+rlI6ZLF6s971nT/Q8XbiAi48d0/+7bqis56hRfDBE7tUAABP+SURBVFq9qA8t8GxQVlWf7rZiRWOvoK5FVKnUZ15kKaealNGRNNGE5ZJInSPSlzJo3Cl2CqV5A4hrkztXqS99L6EWTySdsFaLZsuYtvjcW/b++vrSa7/Etd924fT3R68D153k1rWxM2nctyOzbpI7xa6tYx9nw4b6DB6fBe7K1aIUY9ACJ6XCBC+NBZQnOGkYH9eWVK2m92H2BWjranQ0DByKxE91BqRndMQFqUzJhOlpSNy+3XVHR3UwdO9ebeHbQ/tNMM5UQrSDcOPjwMqV+vdaDXjf+4Cf/jQMPNrlZZNq8ZisC6OiPvSh8Bgm8GoyQoyV/s//HLWMZ2ZCq9S0LSbYOZfRAtSX8wWAVauAr35VW7KViv6Y8rRuoHx0NAxoz8zotlltmrPWzTYmE8lY1r4gNQA89BBw7lxU5ksvBd75TmDDBp39ZNdyca+dgqACJ92HXUPa3IBpyi9JQVSrwPLlwHPPhYrBLURlimFlKdBkk2VkYvBaHTtHJBBtu1GQJpvFV5Pc1xe28pqaAv7mb+rbMj2t13v00fhaPO4IVFN64MIF/cBzy6xWq8B3vhM9TrWqs24Av7L2jbI8dcpfznfDBuDmm8N6KSLapWFGzPqKYBne9S59fFNnxT2vZhtfeqiNySrq7w/Xe+kl4OmngZtvxtXr1+s+N66atWvDbQscmUwFTroPc3ObtDLjj41TrGkKAtDpbCdO1Bei2rlT79tOO2v1jTY8DGzejLOPPYZL7rpLL4sbRh9X28TInVS24fTp+DaYfHmldC49oBXgo4/622vHBI4erVe2ts/51CldkMoQ9O+5X/kV/d2nrH21W/7wD6OW9623auVt3kzMG9LMjPZH2/1o+m71ah07mZrSffv2twN33JF8Xu3rzR5XYHLIAa38TQzm/vvrCqZVTE6+O4lGo8XuMkIFTroP9+Y2gce4WeSzKAhfAHR8PDroJmnmGne7PBZV8Ebx+slJbcnaeeZ23RR3AMvmzfq1/vbbw+MkTRDyta/Ft8EoIhXkjW/dGlrTcTLYVRbtWjHmwWHa+Xu/Fx6jWg0tUHOu4mrKuLVb7MEyAPDGN8a/FcTVPlm8GHj44dD9tG1bfYVDl6TAoy/obQen+/uB22+H2r8fYtpvlyu225hlBqO8+BzjRX0YxMwGZVXxwbg8KYRpQb4scxe69UEamTM0Kc/cpKjF1QjJOtTbza2+7bbokHtz7IyTMUSGvlcqen8meGqzdWt9sC+grhZKWiqnHcC1UwTj9mGXQ3BLE9iBTzfNMu26yBJ4dNb5h/vui5/300k5bCSgCeaBl4d5KWvaTZOmbLPedHFZB3FK0p3NZ8WK/O0Ijjtjbm4zMMZkdPjqsrg58GmzFsXVNnGzWt797jC/POnB4Cpmq6ZLZJsbboiud8MNcz8d3rIlzPbIkolx8GD0oZNVbt8gr7hMlSwPxgYyRxIn5856LhOIU+B0oZDOk8VPmFa2N0sw0X3l9s2xmcall2pfuq8dcXIE7oKTO3bgine+Mzqse/Vq3Q47A2Z0tD4HPi6o6sYLrr8+OtnymjVhjZWZmdBtVKmEEwz76oOfORP1B5v6M27w9PbbgW98I2zP7bfP9cXVn/xkmC9tl62N62fjNrL70C6/a58n129tjqGU7i8zPN/NVPG52xqp9xLXft+6q1fnm5g6B1TgpPOk3VRAtpS9NOJ8sUk1plev1oFOs82GDfrja0eSHMPDODU5iSvGx9P99YB/goksMtnKG4gqD3vgiplgOK4++ObN2h/sFg5zFZDJtjC+evN9dBQVe7BLWhaRwXeefZNSu37rvXvDbKKHH66vAe/21+SklsdM0mxqrh85Ep3gIa29SdjXUUFTFlKBk86TZl0bsljZSWR5CPgssAMH/IX8G5EjS0APiFpsJl2uEZns392iTnYg0ART7ZlpTPGpmRlt1cZNobZ2bTRtzoet/NOCwO55HhuLjsa8+27gb/82mgXz2GPRB1Pcg3l0VOduf+c7ev1779W/3XNPmBMPZJvgIQnfdZRnpp+MUIGTztMK6zrPsZL2b1vRk5NhydONG+Mn3rX3nWVgj28dt115+iNNJvt3e+CK+Wsq/AFRxTU87Ldks2ThXHMNVKWip5EzJXDNgyivi2JkJFqK1h2QMz6e7qJwSwcYTIlid7nrispLlrfKVuBzjBf1YRAzG5S1g8QFBRvJPnGok7VFw6xz45YAMFUGTbZJUhkBXyA4Jmg7a4bi25krWTJ/fDQ6AYfBDUabYKc7mUaDmSLec9vk9WIDBjEJyYCxkD2DNVpqUfn8umluCHvbZt5WbOvQLi8wO6uHrG/YUN9OX630yUntzjCDrIw1HexfVDCwZc+eMMc+q7vMxZ2Aw+cqiusLUxjNpq9PvxUA2v1iWLEiDO7G4RlFG5m8wrTHl8ffanxavagPLfBsUNYuoJGUwxQyTzGWp12NWHauBZ6UM52Uw16r+Wuwm7RJpx56Yn5+kSQVRsvbn/b6JrWyUqkvnUsLnJAO4vNVJ1mAeYnz6+ZNhWzkTcCV7cSJMFjp1gtJGtHqC4pa+z/78Y/jkiNHkqdJawe+kb127CFPvMHuf4uKOytSm3zgVOCExOEqmiYVz8DERBhMGx6OZnn4Ci35aNQF4WLLkvRwSgq6AonbnfzgB3HJxEQh+c+5yJKpk/W8mv53KiYqEUjSg68g2VMVuIjsAPB+AK8opa4Klt0P4C4A/xSs9vtKqYRCDITMc8bHdcU6u2hVml/XR1EZO0lKrMHfzl15ZXuyi7LEBGzL2P6ed9/Gt719uy7yFeSe/+DjH8fbsjz4WkwWC/xxAFsAjDrLH1JK/XnLW0RILzI2pl+zW+FOaLcLIg9ugK/otmYdOdnICMu4muXGbVStzpW1fWlyEm+ztzN9YHLtgc64UJRS3xKRJS0/MiHziZERzPb1oVrk9FqdxlF4A5/9bPFyZvU1x62XZL37tgGiPvDFi8PMG6C+Dr2vVHALacYHfreIrAZwCMB6pdTPW9QmQnqP4WEcf/BBLDt3rvjBSp3CUXiRGXlsWjnBQVZfs2+9NKvc3WZwULtNfKV1DW6KJlBfKriFiLIc8bEraQv8KcsHPgTgZwAUgM8AWKSUWhOz7VoAawFgaGjo2t27dzfU0PPnz2PhwoUNbVs2KGtvUqSsAxMTuPjYMZxdulT7njvAwMQErl6/HjI1BdXXh/E//mNML1/uXacyNYXZvj4cf/DBptubVXZ7PQBY8vjjeP3hwxClMFup4OSaNTh1xx2RdacGBtB37hymBgbwlkce0e2uVnH6ppvw8o03zh3PnNtFTz6Jt37+83qf1SoEAGZmoJqUdeXKlYeVUsvrfvDlFrofAEsAPJ/3N/fDPPBsUNbepDBZW5xz3HRbghxvr7yNjsRsJUkleO3f7f5MafdcOVl3AulunNRYRBYppV4Kvv4mgOcb2Q8hpAW0q+5GFuygpfEL27QpvS4Ru4CXrwSvrz+ztNveb1JRrRaSJY3wiwBGALxBRF4E8N8BjIjIUmgXykkAv1NYCwkhyXSDUsxKOwuXxZFWgjdLxUh7/fFxLN61S1c5bPN5yJKF8gHP4u0FtIUQ0gjdoBTz0Ok0yCwDe7JUjATmAqGXT04Cu3b559AsEI7EJKQX6LRSLBt5SvAmYQp3mfz+o0d1amGboAInhJBGCdwts5OTqFSrevamAvO+XSqF7p0QQnqZwN1ycs0aPWPR9HT9wJ8CoQVOCCHNMBzMd7pgQWGTF8dBBU4IIa2gA8FkKnBCCGkVbQ4m0wdOCCElhQqcEEJKChU4IYSUFCpwQggpKVTghBBSUqjACSGkpFCBE0JISaECJ4SQkkIFTgghJYUKnBBCSgoVOCGElBQqcEIIKSlU4IQQUlKowAkhpKRQgRNCSEmhAieEkJJCBU4IISWFCpwQQkoKFTghhJQUKnBCCCkpVOCEEFJSUhW4iOwQkVdE5Hlr2SUisk9EfhD8fX2xzSSEEOKSxQJ/HMBNzrJPA9ivlHorgP3Bd0IIIW0kVYErpb4F4J+dxbcC+ELw/xcA3NbidhFCCElBlFLpK4ksAfCUUuqq4PtZpdTFwf8C4Ofmu2fbtQDWAsDQ0NC1u3fvbqih58+fx8KFCxvatmxQ1t5kPskKzC95i5Z15cqVh5VSy93ltWZ3rJRSIhL7FFBKbQOwDQCWL1+uRkZGGjrO2NgYGt22bFDW3mQ+yQrML3k7JWujWSgvi8giAAj+vtK6JhFCCMlCowr8KwDuDP6/E8ATrWkOIYSQrGRJI/wigHEAbxORF0XkwwD+BMB7ReQHAK4PvhNCCGkjqT5wpdQHYn66rsVtIYQQkgOOxCSEkJJCBU4IISWFCpwQQkoKFTghhJQUKnBCCCkpVOCEEFJSqMAJIaSkUIETQkhJoQInhJCSQgVOCCElhQqcEEJKChU4IYSUFCpwQggpKVTghBBSUqjACSGkpFCBE0JISaECJ4SQkkIFTgghJYUKnBBCSgoVOCGElBQqcEIIKSlU4IQQUlKowAkhpKRQgRNCSEmhAieEkJJCBU4IISWl1szGInISwL8CmAEwrZRa3opGEUIISacpBR6wUin1sxbshxBCSA7oQiGEkJLSrAJXAL4hIodFZG0rGkQIISQbopRqfGORy5RSPxGRXwKwD8A9SqlvOeusBbAWAIaGhq7dvXt3Q8c6f/48Fi5c2HBbywRl7U3mk6zA/JK3aFlXrlx52BdjbEqBR3Ykcj+A80qpP49bZ/ny5erQoUMN7X9sbAwjIyONNa5kUNbeZD7JCswveYuWVUS8CrxhF4qIvFZEXmf+B3ADgOcbbyIhhJA8NJOFMgTgr0XE7Od/KaW+3pJWEUIISaVhBa6U+jGAq1vYFkIIITlgGiEhhJQUKnBCCCkpVOCEEFJSqMAJIaSkUIETQkhJoQInhJCSQgVOCCElhQqcEEJKChU4IYSUFCpwQggpKVTghBBSUqjACSGkpFCBE0JISaECJ4SQkkIFTgghJYUKnBBCSgoVOCGElBQqcEIIKSlU4IQQUlKowAkhpKSUQ4GPj2Pxrl3A+HinW0IIIV1D9yvw8XHguutw+Y4dwHXXUYkTQkhA9yvwsTHgwgXI7Cxw4YL+TgghpAQKfGQE6O/HbKUC9Pfr74QQQkqgwIeHgf37cXLNGmD/fv2dEEIIap1uQCaGh3FqchJXUHkTQsgc3W+BE0II8dKUAheRm0Tk+yLyQxH5dKsaRQghJJ2GFbiIVAE8AuBmAG8H8AEReXurGkYIISSZZizwFQB+qJT6sVLqAoDdAG5tTbMIIYSk0YwCvwzA/7O+vxgsI4QQ0gYKz0IRkbUA1gLA0NAQxhociHP+/PmGty0blLU3mU+yAvNL3k7J2owC/wmAN1vf3xQsi6CU2gZgGwCIyD+tXLny/zZ4vDcA+FmD25YNytqbzCdZgfklb9Gy/nvfQlFKNbQ3EakB+EcA10Er7ucA/Bel1ESjLUw53iGl1PIi9t1tUNbeZD7JCswveTsla8MWuFJqWkTuBvA0gCqAHUUpb0IIIfU05QNXSn0NwNda1BZCCCE5KNNIzG2dbkAboay9yXySFZhf8nZE1oZ94IQQQjpLmSxwQgghFqVQ4L1Wc0VEdojIKyLyvLXsEhHZJyI/CP6+PlguIvIXgezfE5FlnWt5fkTkzSJyQET+XkQmROQTwfKek1dEXiMiz4rI8UDWPwqWXy4i3w1k+pKI9AfLFwTffxj8vqST7W8EEamKyFEReSr43pOyishJETkhIsdE5FCwrOPXcNcr8B6tufI4gJucZZ8GsF8p9VYA+4PvgJb7rcFnLYBH29TGVjENYL1S6u0Afg3Ax4Lz14vyTgJ4j1LqagBLAdwkIr8G4E8BPKSUeguAnwP4cLD+hwH8PFj+ULBe2fgEgBes770s60ql1FIrXbDz17BSqqs/AIYBPG193whgY6fb1QK5lgB43vr+fQCLgv8XAfh+8P9WAB/wrVfGD4AnALy31+UF8AsAjgD4VegBHrVg+dz1DJ2COxz8XwvWk063PYeMb4JWXO8B8BQA6WFZTwJ4g7Os49dw11vgmD81V4aUUi8F/58GMBT83zPyB6/N1wD4LnpU3sClcAzAKwD2AfgRgLNKqelgFVueOVmD3/8FwGB7W9wUmwFsADAbfB9E78qqAHxDRA4H5UGALriGyzEjzzxDKaVEpKfSg0RkIYA9AO5VSp0TkbnfeklepdQMgKUicjGAvwbwHzrcpEIQkfcDeEUpdVhERjrdnjbwG0qpn4jILwHYJyL/YP/YqWu4DBZ4pporPcDLIrIIAIK/rwTLSy+/iPRBK+9dSqkvB4t7Vl4AUEqdBXAA2o1wcVB6AojKMydr8Pu/A3CmzU1tlF8H8J9E5CR0Ken3APg8elNWKKV+Evx9BfrBvAJdcA2XQYE/B+CtQXS7H8B/BvCVDrepCL4C4M7g/zuhfcVm+eogsv1rAP7Fem3rekSb2tsBvKCU+pz1U8/JKyK/GFjeEJGLoH39L0Ar8t8OVnNlNX3w2wC+qQKnabejlNqolHqTUmoJ9D35TaXUHehBWUXktSLyOvM/gBsAPI9uuIY7HRzIGEC4Bbpw1o8A/LdOt6cF8nwRwEsApqD9Yx+G9gfuB/ADAM8AuCRYV6CzcH4E4ASA5Z1uf05ZfwPaf/g9AMeCzy29KC+A/wjgaCDr8wD+MFh+BYBnAfwQwP8BsCBY/prg+w+D36/otAwNyj0C4KlelTWQ6XjwmTA6qBuuYY7EJISQklIGFwohhBAPVOCEEFJSqMAJIaSkUIETQkhJoQInhJCSQgVOCCElhQqcEEJKChU4IYSUlP8PUbTdinuFp/QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "loading time is: 1.579648602000816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4JBnIPwRgRa"
      },
      "source": [
        "#### To change lr mid-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL4U3_9hH1sp"
      },
      "source": [
        "for i in range(len(optimizer.param_groups)):\n",
        "   scheduler.optimizer.param_groups[i]['lr'] = 0.0000625        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQDFUeWr04yR"
      },
      "source": [
        "### Mapper\n",
        "* Maps the predicted output into : confidence , x (from 0 to 512) , y (from 0 to 512) , direction-x (from 0 to 512) , direction-y (from 0 to 512) , shape of marking point\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHMZpGu3evqG"
      },
      "source": [
        "def mapper(prediction_in):\n",
        "  prediction = torch.clone(prediction_in)\n",
        "  for i in range(16):\n",
        "    for j in range(16):\n",
        "      prediction[:,1,i,j] =  prediction[:,1,i,j] + 16 + (32 * i)\n",
        "      prediction[:,2,i,j] =  prediction[:,2,i,j] + 16 + (32 * j)\n",
        "\n",
        "      cos_value = prediction[:,3, i, j] / 16\n",
        "      sin_value = prediction[:,4, i, j] / 16\n",
        "      # direction = math.atan(sin_value/cos_value) # if we want to know the angle\n",
        "      x_val_mapped = prediction[:,1,i,j]\n",
        "      y_val_mapped = prediction[:,2,i,j]\n",
        "      x_dir = x_val_mapped + (40 * cos_value)\n",
        "      y_dir = y_val_mapped + (40 * sin_value)\n",
        "      prediction[:,3,i,j] = x_dir\n",
        "      prediction[:,4,i,j] = y_dir\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoKoQdRcGq0_"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQLmAmpcGq1A"
      },
      "source": [
        "def predict(image):\n",
        "    out = model(image).to(device)\n",
        "    out = out.reshape((-1,6,16,16))\n",
        "    out = mapper(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utgdbSv1Gq1A"
      },
      "source": [
        "## Visualizer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM_Hn3tKGq1A"
      },
      "source": [
        "def visualize_after_thres(image,prediction):\n",
        "    pre = prediction\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    for i in range(len(pre)):\n",
        "        plt.plot([pre[i,1]],[pre[i][2]],'o')\n",
        "        plt.plot([pre[i,3]],[pre[i][4]],'x')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGOp182yGq1A"
      },
      "source": [
        "## Remove points lower than Thresthold \n",
        "\n",
        "* takes the predicted point and the threshold, check if the confidence value is less than this threshold then we remove this point\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apNX4eEIGq1B"
      },
      "source": [
        "def get_predicted_points(prediction, thresh): # prediction (training,6,16,16)\n",
        "    \"\"\"Get marking points from one predicted feature map.\"\"\"\n",
        "    assert isinstance(prediction, torch.Tensor)\n",
        "    if len(prediction.shape) == 3:\n",
        "        prediction = prediction.reshape((1,6,16,16))\n",
        "    num_training_examples = prediction.shape[0]\n",
        "    predicted_points = []\n",
        "    prediction = prediction.detach().cpu()\n",
        "    \n",
        "    index = (torch.greater_equal(prediction[:,0,:,:],thresh))\n",
        "    \n",
        "    prediction = prediction.permute(0,2,3,1)\n",
        "    \n",
        "    for i in range(num_training_examples):\n",
        "        predicted_points.append(prediction[i,index[i,:,:]])\n",
        "\n",
        "    predicted_points_copy = []\n",
        "    for i in range(len(predicted_points)):\n",
        "      predicted_points_copy.append(torch.clone(predicted_points[i]))\n",
        "\n",
        "    for i in range(len(predicted_points)): # 3la el training examples\n",
        "      for j in range(len(predicted_points[i])): # 3la el points\n",
        "        if predicted_points[i][j][1] < 10 and  predicted_points[i][j][2] < 10:  # remove points with negative x , y values\n",
        "           predicted_points_copy[i] = torch.cat([predicted_points_copy[i][0:j,:], predicted_points_copy[i][j+1:,:]])\n",
        "    return (predicted_points_copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybVT_AzAGq1C"
      },
      "source": [
        "## Remove Row from Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTOtfoweGq1C"
      },
      "source": [
        "def remove_row_ls(tens,row_index_ls):\n",
        "    tens_copy = torch.clone(tens)\n",
        "    ls = []\n",
        "    for i in range(tens_copy.shape[0]):\n",
        "        ls.append(i)\n",
        "    ls = torch.tensor(ls)\n",
        "    #index = []\n",
        "    for i in range(len(row_index_ls)):\n",
        "        index = ls[ls!=row_index_ls[i]]\n",
        "        ls = index\n",
        "    index = torch.tensor(index)\n",
        "    return torch.index_select(tens_copy, 0, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flFDBP-4Gq1C"
      },
      "source": [
        "## Non-max suppression for near points\n",
        "\n",
        "\n",
        "*   take predicted points and check if there is more than one point close to each other it will remove all of the except the one which have the highest confidence\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBVRZnGuGq1D"
      },
      "source": [
        "def non_maximum_suppression(pred_points): # pred_points (training,num_points,6) (list)\n",
        "    \"\"\"Perform non-maxmum suppression on marking points.\"\"\"\n",
        "    pred_copy = pred_points\n",
        "    threshold_near = 40 # expermintal\n",
        "    for k , tens in enumerate(pred_copy):\n",
        "        index_arr = []\n",
        "        for i in range(tens.shape[0]):\n",
        "            for j in range(i + 1, tens.shape[0]):\n",
        "                i_x = tens[i][1]\n",
        "                i_y = tens[i][2]\n",
        "                j_x = tens[j][1]\n",
        "                j_y = tens[j][2]\n",
        "                abs_x = abs(j_x - i_x)\n",
        "                abs_y = abs(j_y - i_y)\n",
        "                abs_dis = math.sqrt(math.pow(abs_x,2) + math.pow(abs_y,2))\n",
        "                if abs_dis <= threshold_near:\n",
        "                    idx = i if tens[i][0] < tens[j][0] else j\n",
        "                    index_arr.append(idx)\n",
        "  \n",
        "        if(len(index_arr)!=0):\n",
        "          pred_copy[k] = remove_row_ls(tens,index_arr)  \n",
        "    return pred_copy        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq-yzosaGq1D"
      },
      "source": [
        "## Calculate Distance between two points "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCuBfJCpGq1E"
      },
      "source": [
        "def calc_point_squre_dist(point_a, point_b):\n",
        "    \"\"\"Calculate distance between two marking points.\"\"\"\n",
        "    x_a = point_a[1]\n",
        "    y_a = point_a[2]\n",
        "    x_b = point_b[1]\n",
        "    y_b = point_b[2]\n",
        "\n",
        "    distx = x_a - x_b\n",
        "    disty = y_a - y_b\n",
        "    dist = math.sqrt(math.pow(distx,2) + math.pow(disty,2))\n",
        "    return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhHCIsauGq1E"
      },
      "source": [
        "## Check the third point\n",
        "\n",
        "\n",
        "*   function checks if the line passes between the two marking points conatins another third point between them or not\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9HJAR7Gq1E"
      },
      "source": [
        "angle_threhold = 5\n",
        "def pass_through_third_point(marking_points, i, j):\n",
        "    x_1 = marking_points[i][1]\n",
        "    y_1 = marking_points[i][2]\n",
        "    x_2 = marking_points[j][1]\n",
        "    y_2 = marking_points[j][2]\n",
        "    for point_idx, tens in enumerate(marking_points):\n",
        "        if point_idx == i or point_idx == j:\n",
        "            continue\n",
        "        x_0 = tens[1]\n",
        "        y_0 = tens[2]\n",
        "        vec1 = np.array([x_0 - x_1, y_0 - y_1])\n",
        "        vec2 = np.array([x_2 - x_1, y_2 - y_1])\n",
        "        vec1 = vec1 / np.linalg.norm(vec1)\n",
        "        vec2 = vec2 / np.linalg.norm(vec2)\n",
        "        angle = math.acos(np.dot(vec1, vec2)) * (180/math.pi)\n",
        "        if angle < angle_threhold:\n",
        "            return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKcfT_Fpr92"
      },
      "source": [
        "epsilon = 0.001  # check on number\n",
        "\n",
        "# check if c between a,b\n",
        "def isBetween(a, b, c):\n",
        "    crossproduct = (c[2] - a[2]) * (b[1] - a[1]) - (c[1] - a[1]) * (b[2] - a[2])\n",
        "    print (\"crossproduct\",crossproduct)\n",
        "    # compare versus epsilon for floating point values, or != 0 if using integers \n",
        "    # sin 0 =0 , check theta >0 (not parallel)\n",
        "    if abs(crossproduct) > epsilon:\n",
        "        return False\n",
        "\n",
        "    # cos 180 = -1, check that they are in the same direction\n",
        "    dotproduct = (c[1] - a[1]) * (b[1] - a[1]) + (c[2] - a[2])*(b[2] - a[2])\n",
        "    print (\"dotproduct\",dotproduct)\n",
        "    if dotproduct < 0:\n",
        "        return False\n",
        "\n",
        "    squaredlengthba = (b[1] - a[1])*(b[1] - a[1]) + (b[2] - a[2])*(b[2] - a[2])\n",
        "    print (\"squaredlengthba\",squaredlengthba)\n",
        "\n",
        "    if dotproduct > squaredlengthba:\n",
        "        return False\n",
        "\n",
        "    return True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvmI5lrcGq1F"
      },
      "source": [
        "## Calculate Direction(angle)\n",
        "\n",
        "\n",
        "*   based on the x_differnce and the y_differnce to determine the angle between them (inwhich quad they loacte)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FirSpR4HGq1F"
      },
      "source": [
        "def calc_angle(p1,p2):\n",
        "  y_diff = p2[1]- p1[1]\n",
        "  x_diff = p2[0] - p1[0]\n",
        "  if x_diff == 0 and y_diff ==0 :\n",
        "    return 0\n",
        "  theta = math.atan(abs( y_diff/x_diff)) * (180/math.pi)  \n",
        "  if x_diff >=0 and y_diff >=0:\n",
        "    return theta\n",
        "  elif x_diff < 0 and y_diff >=0:\n",
        "    return 180- theta\n",
        "  elif x_diff < 0 and y_diff < 0:\n",
        "    return - 180 + theta\n",
        "  elif x_diff > 0 and y_diff <0:\n",
        "    return -1* theta\n",
        "  else:\n",
        "    return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BstBwm0F73oM"
      },
      "source": [
        "def calc_angle_vector(p1):\n",
        "  \n",
        "  y_diff = p1[1]\n",
        "  x_diff = p1[0] \n",
        "  if x_diff == 0 and y_diff ==0 :\n",
        "    return 0\n",
        "  theta = math.atan(abs( y_diff/x_diff)) * (180/math.pi)\n",
        "  if x_diff >=0 and y_diff >=0:\n",
        "    return theta\n",
        "  elif x_diff < 0 and y_diff >=0:\n",
        "    return 180- theta\n",
        "  elif x_diff < 0 and y_diff < 0:\n",
        "    return  180+theta       #270 - theta\n",
        "  elif x_diff > 0 and y_diff <0:\n",
        "    return -1* theta\n",
        "  else:\n",
        "    return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5EkPBFGGq1G"
      },
      "source": [
        "## Calculate difference in direction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R16BSWM18BFQ"
      },
      "source": [
        "def abs_direction_diff(direction_a, direction_b):\n",
        "    \"\"\"Calculate the angle between two direction.\"\"\"\n",
        "    diff = abs(abs(direction_a) - abs(direction_b))\n",
        "    return diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqm16-Jz8FnO"
      },
      "source": [
        "def direction_diff(direction_a, direction_b):\n",
        "    \"\"\"Calculate the angle between two direction.\"\"\"\n",
        "    diff = abs((direction_a) - (direction_b))\n",
        "    return diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENV0YrjhGq1G"
      },
      "source": [
        "## Determine Point Shape\n",
        "\n",
        "\n",
        "*   determine the shape of the slot line based on the vector joining the two slot points and the vector between the point and its direction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wakZ2SmWGq1G"
      },
      "source": [
        "none = 0\n",
        "l_down = 2\n",
        "t_down = 3\n",
        "t_middle = 4\n",
        "t_up = 5\n",
        "l_up = 6 \n",
        "\n",
        "def detemine_point_shape(point, vector):\n",
        "    \"\"\"Determine which category the point is in.\"\"\"\n",
        "    vec_direct =calc_angle_vector(vector) #*(180/math.pi)\n",
        "   # vec_direct_up = calc_angle_vector([-1*vector[0], vector[1]]) #*(180/math.pi)\n",
        "    vec_direct_up = 180 - vec_direct\n",
        "    vec_direct_down = calc_angle_vector([vector[0], -1*vector[1]]) #*(180/math.pi)\n",
        "    marking_direction =  calc_angle ([point[1],point[2]],[point[3],point[4]]) #*(180/math.pi)\n",
        "    print('vector',vec_direct,'mark',marking_direction,'v up',vec_direct_up,'v down',vec_direct_down)\n",
        "    if point[5] < 50:\n",
        "        if abs_direction_diff(vec_direct, marking_direction) >60 and  abs_direction_diff(vec_direct, marking_direction) <135:  # < angle 13.5\n",
        "            print('ana middle t')\n",
        "            return t_middle\n",
        "        \n",
        "        if direction_diff(vec_direct_down, marking_direction) <50:\n",
        "            print('ana down t')\n",
        "            return t_down\n",
        "    else:\n",
        "      difference = marking_direction - vec_direct_down \n",
        "      if difference> 170:\n",
        "          print('ana down l')\n",
        "          return l_down\n",
        "      if difference < 170:\n",
        "          print('ana up l')\n",
        "          return l_up\n",
        "    return none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hxifguLGq1G"
      },
      "source": [
        "## Pair Marking Points to form slots \n",
        "\n",
        "\n",
        "\n",
        "*  according to the shape returned from the \"determine_point_shape\" function we check whether these two shapes could form a slot or not.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4obe09Gq1H"
      },
      "source": [
        "def pair_marking_points(point_a, point_b):\n",
        "    \"\"\"See whether two marking points form a slot.\"\"\"\n",
        "    vector_ab = np.array([point_b[1] - point_a[1], point_b[2] - point_a[2]])\n",
        "    vector_ab = vector_ab / np.linalg.norm(vector_ab)\n",
        "    point_shape_a = detemine_point_shape(point_a, vector_ab)\n",
        "    point_shape_b = detemine_point_shape(point_b, -vector_ab)\n",
        "    none = 0\n",
        "    l_down = 2\n",
        "    t_down = 3\n",
        "    t_middle = 4\n",
        "    t_up = 5\n",
        "    l_up = 6 \n",
        "    #print(\"point shapes\",point_shape_a,point_shape_b)\n",
        "    if ( point_shape_a == l_up and point_shape_b == l_up)  :\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if ( point_shape_a == l_down and point_shape_b == l_down)  :\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if  ( point_shape_a == t_middle and point_shape_b == t_middle ) :\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if (point_shape_a == t_down and point_shape_b == t_down) :  \n",
        "      vect1 = np.array([point_a[3] - point_a[1], point_a[4] - point_a[2]])\n",
        "      vect1 = vect1 / np.linalg.norm(vect1)\n",
        "      vect2 = np.array([point_b[3] - point_b[1], point_b[4] - point_b[2]])\n",
        "      vect2 = vect2 / np.linalg.norm(vect2)\n",
        "      dot_product = (np.dot(vect1, vect2))\n",
        "      print('dot',dot_product)\n",
        "      if dot_product > 0.3:\n",
        "        return [1,point_shape_a,point_shape_b]\n",
        "      else:\n",
        "        return [0]\n",
        "    if (point_shape_a == l_up and point_shape_b == t_middle) or (point_shape_b == l_up and point_shape_a == t_middle):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if (point_shape_a ==t_middle  and point_shape_b ==l_down)  or (point_shape_b ==t_middle  and point_shape_a ==l_down):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if (point_shape_a ==t_middle  and point_shape_b ==l_up)  or (point_shape_b ==t_middle  and point_shape_a ==l_up):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if point_shape_a == t_up and point_shape_b == l_up or (point_shape_b == t_up and point_shape_a == l_up ):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    #if point_shape_a == t_up and point_shape_b == t_up:\n",
        "     # return 1\n",
        "    if (point_shape_a == l_down and point_shape_b == l_down) :\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if (point_shape_a == l_down and point_shape_b == t_down) or (point_shape_b == l_down and point_shape_a == t_down):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    if (point_shape_a == t_down and point_shape_b == l_up) or (point_shape_b == t_down and point_shape_a == l_up):\n",
        "      return [1,point_shape_a,point_shape_b]\n",
        "    \n",
        "    return [0]                         \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDva8k_0Gq1H"
      },
      "source": [
        "## Forming Slots\n",
        "\n",
        "*   the function gets the predicted marking points and then we loop on point by point with the remaining ones and check if they lie between either parallel or perpendicular distance range and then pass it to determine point shape, pair marking point function and based on the returned result it append the slot details (points forming it and its type) to the slot list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdjJ-vhH-Bfj"
      },
      "source": [
        "perpend_min = 120\n",
        "perpend_max = 190  \n",
        "parallel_min = 340 \n",
        "parallel_max = 370 \n",
        "\n",
        "\n",
        "def inference_slots(marking_points):\n",
        "    \"\"\"Inference slots based on marking points.\"\"\"\n",
        "    num_detected = marking_points.shape[0]\n",
        "    print('numebr of points',num_detected)\n",
        "    perpen_parallel = 0  # perpendicular = 1 , parallel = 2\n",
        "    \n",
        "    slot ={}\n",
        "    slots = []\n",
        "\n",
        "    marks_list = set()\n",
        "    slots_list = []\n",
        "    for i in range(num_detected - 1):\n",
        "        for j in range(i + 1, num_detected):\n",
        "            #print (i,j)\n",
        "            point_i = marking_points[i]\n",
        "            point_j = marking_points[j]\n",
        "            #print('poin i and j',point_i,point_j)\n",
        "            # Step 1: length filtration.\n",
        "            distance = calc_point_squre_dist(point_i, point_j)\n",
        "            print('distance',distance)\n",
        "            #print (\"distance\",distance)\n",
        "            if not (perpend_min <= distance <= perpend_max\n",
        "                    or parallel_min <= distance <= parallel_max):\n",
        "                continue\n",
        "                \n",
        "            # Step 2: pass through filtration.\n",
        "            if pass_through_third_point(marking_points, i, j) and pass_through_third_point(marking_points, j, i):\n",
        "                continue\n",
        "            result = pair_marking_points(point_i, point_j)\n",
        "            #print(\"result\",result)\n",
        "            if  (perpend_min <= distance <= perpend_max):\n",
        "                perpen_parallel = 1 # perpendiculer\n",
        "            elif  (parallel_min <= distance <= parallel_max):\n",
        "                perpen_parallel = 2 # parallel\n",
        "\n",
        "            \n",
        "            if len(result) <= 1:\n",
        "              if result ==0:\n",
        "                print('no pair')\n",
        "                continue\n",
        "            else:\n",
        "              if result[0] == 1:\n",
        "                print('pair',i,j,marking_points[i][1] - marking_points[j][1],marking_points[i][2] - marking_points[j][2])\n",
        "                print('........distnace',distance)\n",
        "                first_point,second_point = order_pair(marking_points[i],marking_points[j])\n",
        "                print('done order')\n",
        "                #if abs(marking_points[i][1] - marking_points[j][1]) <150 and abs(marking_points[i][2] - marking_points[j][2])<150:\n",
        "                test1 = {'x1': first_point[1], 'y1': first_point[2],'dir_x1': first_point[3], 'dir_y1':first_point[4],\n",
        "                    'x2': second_point[1],'y2': second_point[2],'dir_x2': second_point[3], 'dir_y2': second_point[4],\n",
        "                    'type': perpen_parallel,'type1':result[1],'type2':result[2]}\n",
        "\n",
        "                marks_list.add((marking_points[i],marking_points[j]))\n",
        "                slots_list.append((i+1,j+1,perpen_parallel))\n",
        "                slot.update(test1.copy())\n",
        "                slots.append(slot.copy())\n",
        "\n",
        "                #print('updated slot',slots)\n",
        "                #break\n",
        "    slots2={'marks':  list(marks_list),'slots':slots_list}\n",
        "    return slots,slots2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbO0o5xq_u4A"
      },
      "source": [
        "### Order points pair clockwise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXXAUaTI_nMC"
      },
      "source": [
        "def order_pair(point1,point2):\n",
        "  if abs(point2[2]-point1[2])<20:\n",
        "    if point2[1] > point1[1]:\n",
        "      return point2,point1\n",
        "    else:\n",
        "      return point1,point2\n",
        "  else:\n",
        "    if max(point2[1] , point1[1]) >255:\n",
        "      if point2[2] < point1[2]:\n",
        "        return point2,point1\n",
        "      else:\n",
        "        return point1,point2\n",
        "    elif max(point2[1] , point1[1]) <255:\n",
        "      print('first half')\n",
        "      if point1[2]> point2[2] :\n",
        "        print('1,2')\n",
        "        return point1,point2\n",
        "      else:\n",
        "        return point2,point1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kwteAfC_5dt"
      },
      "source": [
        "### Slot visualizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spSBf4a4_qKl"
      },
      "source": [
        "def visualize_slot(image,prediction):\n",
        "    \n",
        "    slots = prediction\n",
        "    print('aana hrsm',slots)\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    for i in range(len(slots)):\n",
        "     #   plt.plot([pre[i][1]],[pre[i][2]],'o')\n",
        "      #  plt.plot([pre[i][3]],[pre[i][4]],'o')\n",
        "       x = [slots[i]['x1'],slots[i]['x2']]\n",
        "       y= [slots[i]['y1'],slots[i]['y2']]\n",
        "       mark1_x = [slots[i]['x1'],slots[i]['dir_x1']]\n",
        "       mark1_y = [slots[i]['y1'],slots[i]['dir_y1']]\n",
        "       mark2_x = [slots[i]['x2'],slots[i]['dir_x2']]\n",
        "       mark2_y = [slots[i]['y2'],slots[i]['dir_y2']]\n",
        "      \n",
        "       p1 = '1'\n",
        "       p2 = '2'\n",
        "       plt.text(slots[i]['x1']+15, slots[i]['y1']  , p1,fontsize=10 , color='white')\n",
        "       plt.text(slots[i]['x2']+15, slots[i]['y2'] , p2,fontsize=10 , color='white')\n",
        "       txt = 'slot '+ str(i+1)\n",
        "       plt.text(max(slots[i]['x1'],slots[i]['x2']),(slots[i]['y1']+slots[i]['y2']) /2 +15 , txt,fontsize=12 , color='red')\n",
        "       #dir_x = [slots[i]['dir_x1'],slots[i]['dir_x2']]\n",
        "       #dir_y = [slots[i]['dir_y1'],slots[i]['dir_y2']]\n",
        "       plt.plot(x,y,mark1_x,mark1_y,mark2_x, mark2_y,linewidth=3, markersize=3, color='green')\n",
        "       \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AkhpPqpADyB"
      },
      "source": [
        "### Testing Slot detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBW_Erk7AIL-"
      },
      "source": [
        "k = 3886\n",
        "model= model.eval()\n",
        "start = timeit.default_timer()\n",
        "predict_awal2 = predict(park_dataset[k]['image'].reshape((1,3,512,512)).to(device))\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)\n",
        " \n",
        "predict_ba3d2= get_predicted_points(predict_awal2,80)\n",
        "\n",
        "predict_ba3d2= non_maximum_suppression(predict_ba3d2)\n",
        "res3,res_vac = inference_slots(predict_ba3d2[0])\n",
        "visualize_after_thres(park_dataset[k]['image'],predict_ba3d2[0])\n",
        "visualize_slot(park_dataset[k]['image'],res3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-5s2tN5V28q"
      },
      "source": [
        "### initialize marking points predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZgW5TCgVxZg"
      },
      "source": [
        "def init_marking_points_model():\n",
        "  model = ConvNet().to(device)\n",
        "  checkpoint = torch.load(r'/model_weights') # weights path\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuWgoq1tV8mV"
      },
      "source": [
        "### Takes an image returns predicted Marking points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-wzwGM-V13L"
      },
      "source": [
        "\n",
        "def image_predict_marking_points(input_image,model):\n",
        "  image_transform = ToTensor()\n",
        "  input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "  input_image = image_transform(input_image)\n",
        "\n",
        "  # if image is not 512 x 512\n",
        "  # input_image = input_image.permute(1,2,0)\n",
        "  # input_image = transform.resize(input_image, (512, 512))\n",
        "  # input_image = torch.tensor(input_image).permute(2,0,1)\n",
        "\n",
        "  model  = model.eval()\n",
        "  predict_awal = predict(input_image.reshape((1,3,512,512)).to(device))\n",
        "  predict_ba3d = get_predicted_points(predict_awal,70)\n",
        "  predict2 = non_maximum_suppression(predict_ba3d)\n",
        "  visualize_after_thres(input_image,predict2[0])\n",
        "  return predict2  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}